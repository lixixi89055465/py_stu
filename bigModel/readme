# 使用 Colab 执行

pip install data-utilities datasets torch transformers ollama config torch transformers jsonlines pandas

os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"  # 使用国内hf镜像
os.environ["CUDA_VISIBLE_DEVICES"] = "2"
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"
/home/sdb2/aidata/workspace/py_stu
git clone https://github.com/facebookresearch/llama.git
cd llama
pip install -r requirements.txt
pip install -e .



#export PATH="/usr/local/cuda-10.1/bin:$PATH"
#export LD_LIBRARY_PATH="/usr/local/cuda-10.1/lib64:$LD_LIBRARY_PATH"
#export PATH="/usr/local/cuda-10.0/bin:$PATH"
#export LD_LIBRARY_PATH="/usr/local/cuda-10.0/lib64:$LD_LIBRARY_PATH"

#export PATH="/usr/local/cuda-11.1/bin:$PATH"
#export LD_LIBRARY_PATH="/usr/local/cuda-11.1/lib64:$LD_LIBRARY_PATH"
#export PATH="/usr/local/cuda-10.2/bin:$PATH"
#export LD_LIBRARY_PATH="/usr/local/cuda-10.2/lib64:$LD_LIBRARY_PATH"
export PATH="/usr/local/cuda-12.1/bin:$PATH"
export LD_LIBRARY_PATH="/usr/local/cuda-12.1/lib64:$LD_LIBRARY_PATH"
export HF_ENDPOINT=https://hf-mirror.com
export PATH=$PATH:/home/dske/anaconda3/envs/mzx/bin
