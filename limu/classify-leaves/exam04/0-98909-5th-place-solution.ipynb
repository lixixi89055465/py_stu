{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adopted-reminder",
   "metadata": {
    "papermill": {
     "duration": 0.012206,
     "end_time": "2021-06-28T13:07:49.143549",
     "exception": false,
     "start_time": "2021-06-28T13:07:49.131343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "感谢Neko Kiku提供的baseline，本文使用了其中上传的数据集。\n",
    "\n",
    "#### 本文的主要思路如下：\n",
    "\n",
    "* 数据增强：\n",
    "resize 320, HorizontalFlip, VerticalFlip, Rotate, RandomBrightnesContrasr, ShiftScaleRotate, Normalize\n",
    "* 模型：\n",
    "seresnext50和resnet50\n",
    "* 优化器：\n",
    "AdamW CosineAnnealingLR\n",
    "* 其他：\n",
    "5折交叉验证， 最终结果为五折准确率最高平均， 两个网络各自平均后再做平均。\n",
    "loss就是CrossEntropy。\n",
    "\n",
    "### 有任何问题欢迎讨论，我比较懒很多东西没有详细写。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "offensive-keeping",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T13:07:49.175643Z",
     "iopub.status.busy": "2021-06-28T13:07:49.175144Z",
     "iopub.status.idle": "2021-06-28T13:07:56.771709Z",
     "shell.execute_reply": "2021-06-28T13:07:56.771004Z",
     "shell.execute_reply.started": "2021-06-28T11:13:03.046565Z"
    },
    "papermill": {
     "duration": 7.617115,
     "end_time": "2021-06-28T13:07:56.771854",
     "exception": false,
     "start_time": "2021-06-28T13:07:49.154739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\r\n",
      "  Downloading timm-0.4.9-py3-none-any.whl (346 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 346 kB 4.4 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm) (1.7.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.8.1)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (0.18.2)\r\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (3.7.4.3)\r\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (0.6)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (1.19.5)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (7.2.0)\r\n",
      "Installing collected packages: timm\r\n",
      "Successfully installed timm-0.4.9\r\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sized-vitamin",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T13:07:56.805960Z",
     "iopub.status.busy": "2021-06-28T13:07:56.805194Z",
     "iopub.status.idle": "2021-06-28T13:08:00.692494Z",
     "shell.execute_reply": "2021-06-28T13:08:00.692052Z",
     "shell.execute_reply.started": "2021-06-28T11:13:09.550479Z"
    },
    "papermill": {
     "duration": 3.907036,
     "end_time": "2021-06-28T13:08:00.692623",
     "exception": false,
     "start_time": "2021-06-28T13:07:56.785587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, cross_val_score\n",
    "\n",
    "# Metric\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "# Augmentation\n",
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-taxation",
   "metadata": {
    "papermill": {
     "duration": 0.013024,
     "end_time": "2021-06-28T13:08:00.720318",
     "exception": false,
     "start_time": "2021-06-28T13:08:00.707294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "固定随机种子，保证结果可复现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "national-clearing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T13:08:00.751503Z",
     "iopub.status.busy": "2021-06-28T13:08:00.750859Z",
     "iopub.status.idle": "2021-06-28T13:08:00.756206Z",
     "shell.execute_reply": "2021-06-28T13:08:00.755749Z",
     "shell.execute_reply.started": "2021-06-28T11:13:13.599644Z"
    },
    "papermill": {
     "duration": 0.02298,
     "end_time": "2021-06-28T13:08:00.756318",
     "exception": false,
     "start_time": "2021-06-28T13:08:00.733338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 415\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-biology",
   "metadata": {
    "papermill": {
     "duration": 0.012883,
     "end_time": "2021-06-28T13:08:00.782250",
     "exception": false,
     "start_time": "2021-06-28T13:08:00.769367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "把数据读进来，并且把label搞定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "smaller-piano",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T13:08:00.814766Z",
     "iopub.status.busy": "2021-06-28T13:08:00.814245Z",
     "iopub.status.idle": "2021-06-28T13:08:00.872412Z",
     "shell.execute_reply": "2021-06-28T13:08:00.871868Z",
     "shell.execute_reply.started": "2021-06-28T11:13:13.610069Z"
    },
    "papermill": {
     "duration": 0.077258,
     "end_time": "2021-06-28T13:08:00.872540",
     "exception": false,
     "start_time": "2021-06-28T13:08:00.795282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '../input/classify-leaves'\n",
    "labels_file_path = os.path.join(path, 'train.csv')\n",
    "sample_submission_path = os.path.join(path, 'test.csv')\n",
    "\n",
    "df = pd.read_csv(labels_file_path)\n",
    "sub_df = pd.read_csv(sample_submission_path)\n",
    "labels_unique = df['label'].unique()\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df['label'])\n",
    "df['label'] = le.transform(df['label'])\n",
    "label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "label_inv_map = {v: k for k, v in label_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-letters",
   "metadata": {
    "papermill": {
     "duration": 0.012887,
     "end_time": "2021-06-28T13:08:00.898848",
     "exception": false,
     "start_time": "2021-06-28T13:08:00.885961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adapted-receipt",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T13:08:00.933625Z",
     "iopub.status.busy": "2021-06-28T13:08:00.932416Z",
     "iopub.status.idle": "2021-06-28T13:08:00.934732Z",
     "shell.execute_reply": "2021-06-28T13:08:00.935161Z",
     "shell.execute_reply.started": "2021-06-28T11:13:13.674123Z"
    },
    "papermill": {
     "duration": 0.023426,
     "end_time": "2021-06-28T13:08:00.935281",
     "exception": false,
     "start_time": "2021-06-28T13:08:00.911855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Resize(320, 320),\n",
    "            albumentations.HorizontalFlip(p=0.5),\n",
    "            albumentations.VerticalFlip(p=0.5),\n",
    "            albumentations.Rotate(limit=180, p=0.7),\n",
    "            albumentations.RandomBrightnessContrast(),\n",
    "            albumentations.ShiftScaleRotate(\n",
    "                shift_limit=0.25, scale_limit=0.1, rotate_limit=0\n",
    "            ),\n",
    "            albumentations.Normalize(\n",
    "                [0.485, 0.456, 0.406], [0.229, 0.224, 0.225],\n",
    "                max_pixel_value=255.0, always_apply=True\n",
    "            ),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def get_valid_transforms():\n",
    "    return albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Resize(320, 320),\n",
    "            albumentations.Normalize(\n",
    "                [0.485, 0.456, 0.406], [0.229, 0.224, 0.225],\n",
    "                max_pixel_value=255.0, always_apply=True\n",
    "            ),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-batman",
   "metadata": {
    "papermill": {
     "duration": 0.01294,
     "end_time": "2021-06-28T13:08:00.961117",
     "exception": false,
     "start_time": "2021-06-28T13:08:00.948177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "定义Dataset，还有准确率之类的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "seventh-smell",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T13:08:01.131828Z",
     "iopub.status.busy": "2021-06-28T13:08:01.130092Z",
     "iopub.status.idle": "2021-06-28T13:08:01.134319Z",
     "shell.execute_reply": "2021-06-28T13:08:01.133872Z",
     "shell.execute_reply.started": "2021-06-28T11:13:13.684095Z"
    },
    "papermill": {
     "duration": 0.159969,
     "end_time": "2021-06-28T13:08:01.134443",
     "exception": false,
     "start_time": "2021-06-28T13:08:00.974474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LeafDataset(Dataset):\n",
    "    def __init__(self, images_filepaths, labels, transform=None):\n",
    "        self.images_filepaths = images_filepaths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.images_filepaths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = self.labels[idx]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        return image, label\n",
    "\n",
    "def accuracy(output, target):\n",
    "    y_pred = torch.softmax(output, dim=1)\n",
    "    y_pred = torch.argmax(y_pred, dim=1).cpu()\n",
    "    target = target.cpu()\n",
    "\n",
    "    return accuracy_score(target, y_pred)\n",
    "\n",
    "\n",
    "def calculate_f1_macro(output, target):\n",
    "    y_pred = torch.softmax(output, dim=1)\n",
    "    y_pred = torch.argmax(y_pred, dim=1).cpu()\n",
    "    target = target.cpu()\n",
    "\n",
    "    return f1_score(target, y_pred, average='macro')\n",
    "\n",
    "\n",
    "class MetricMonitor:\n",
    "    def __init__(self, float_precision=3):\n",
    "        self.float_precision = float_precision\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n",
    "\n",
    "    def update(self, metric_name, val):\n",
    "        metric = self.metrics[metric_name]\n",
    "\n",
    "        metric[\"val\"] += val\n",
    "        metric[\"count\"] += 1\n",
    "        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \" | \".join(\n",
    "            [\n",
    "                \"{metric_name}: {avg:.{float_precision}f}\".format(\n",
    "                    metric_name=metric_name, avg=metric[\"avg\"],\n",
    "                    float_precision=self.float_precision\n",
    "                )\n",
    "                for (metric_name, metric) in self.metrics.items()\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "def adjust_learning_rate(optimizer, epoch, params, batch=0, nBatch=None):\n",
    "    \"\"\" adjust learning of a given optimizer and return the new learning rate \"\"\"\n",
    "    new_lr = calc_learning_rate(epoch, params['lr'], params['epochs'], batch, nBatch)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = new_lr\n",
    "    return new_lr\n",
    "\n",
    "\n",
    "\"\"\" learning rate schedule \"\"\"\n",
    "def calc_learning_rate(epoch, init_lr, n_epochs, batch=0, nBatch=None, lr_schedule_type='cosine'):\n",
    "    if lr_schedule_type == 'cosine':\n",
    "        t_total = n_epochs * nBatch\n",
    "        t_cur = epoch * nBatch + batch\n",
    "        lr = 0.5 * init_lr * (1 + math.cos(math.pi * t_cur / t_total))\n",
    "    elif lr_schedule_type is None:\n",
    "        lr = init_lr\n",
    "    else:\n",
    "        raise ValueError('do not support: %s' % lr_schedule_type)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-story",
   "metadata": {
    "papermill": {
     "duration": 0.013599,
     "end_time": "2021-06-28T13:08:01.161784",
     "exception": false,
     "start_time": "2021-06-28T13:08:01.148185",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 参数设置 \n",
    "\n",
    "所有模型都用的相同的参数 其实这里应该针对不同模型调整的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "toxic-satellite",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T13:08:01.195829Z",
     "iopub.status.busy": "2021-06-28T13:08:01.195173Z",
     "iopub.status.idle": "2021-06-28T13:08:01.197630Z",
     "shell.execute_reply": "2021-06-28T13:08:01.198072Z",
     "shell.execute_reply.started": "2021-06-28T11:13:13.702823Z"
    },
    "papermill": {
     "duration": 0.022327,
     "end_time": "2021-06-28T13:08:01.198207",
     "exception": false,
     "start_time": "2021-06-28T13:08:01.175880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'model': 'seresnext50_32x4d',\n",
    "    # 'model': 'resnet50d',\n",
    "    'device': device,\n",
    "    'lr': 1e-3,\n",
    "    'batch_size': 64,\n",
    "    'num_workers': 0,\n",
    "    'epochs': 50,\n",
    "    'out_features': df['label'].nunique(),\n",
    "    'weight_decay': 1e-5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-corruption",
   "metadata": {
    "papermill": {
     "duration": 0.013505,
     "end_time": "2021-06-28T13:08:01.225258",
     "exception": false,
     "start_time": "2021-06-28T13:08:01.211753",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 训练\n",
    "\n",
    "为了更快我就注释掉了，有兴趣可以跑一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "controlled-richmond",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T13:08:01.266936Z",
     "iopub.status.busy": "2021-06-28T13:08:01.266377Z",
     "iopub.status.idle": "2021-06-28T13:08:01.270445Z",
     "shell.execute_reply": "2021-06-28T13:08:01.269992Z",
     "shell.execute_reply.started": "2021-06-28T11:13:13.717254Z"
    },
    "papermill": {
     "duration": 0.031897,
     "end_time": "2021-06-28T13:08:01.270555",
     "exception": false,
     "start_time": "2021-06-28T13:08:01.238658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LeafNet(nn.Module):\n",
    "    def __init__(self, model_name=params['model'], out_features=params['out_features'],\n",
    "                 pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(n_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch, params):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.train()\n",
    "    nBatch = len(train_loader)\n",
    "    stream = tqdm(train_loader)\n",
    "    for i, (images, target) in enumerate(stream, start=1):\n",
    "        images = images.to(params['device'], non_blocking=True)\n",
    "        target = target.to(params['device'], non_blocking=True)\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "        f1_macro = calculate_f1_macro(output, target)\n",
    "        acc = accuracy(output, target)\n",
    "        metric_monitor.update('Loss', loss.item())\n",
    "        metric_monitor.update('F1', f1_macro)\n",
    "        metric_monitor.update('Accuracy', acc)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr = adjust_learning_rate(optimizer, epoch, params, i, nBatch)\n",
    "        stream.set_description(\n",
    "            \"Epoch: {epoch}. Train.      {metric_monitor}\".format(\n",
    "                epoch=epoch,\n",
    "                metric_monitor=metric_monitor)\n",
    "        )\n",
    "    return metric_monitor.metrics['Accuracy'][\"avg\"]\n",
    "\n",
    "def validate(val_loader, model, criterion, epoch, params):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.eval()\n",
    "    stream = tqdm(val_loader)\n",
    "    with torch.no_grad():\n",
    "        for i, (images, target) in enumerate(stream, start=1):\n",
    "            images = images.to(params['device'], non_blocking=True)\n",
    "            target = target.to(params['device'], non_blocking=True)\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            f1_macro = calculate_f1_macro(output, target)\n",
    "            acc = accuracy(output, target)\n",
    "            metric_monitor.update('Loss', loss.item())\n",
    "            metric_monitor.update('F1', f1_macro)\n",
    "            metric_monitor.update('Accuracy', acc)\n",
    "            stream.set_description(\n",
    "                \"Epoch: {epoch}. Validation. {metric_monitor}\".format(\n",
    "                    epoch=epoch,\n",
    "                    metric_monitor=metric_monitor)\n",
    "            )\n",
    "    return metric_monitor.metrics['Accuracy'][\"avg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "random-pencil",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T13:08:01.302389Z",
     "iopub.status.busy": "2021-06-28T13:08:01.301841Z",
     "iopub.status.idle": "2021-06-28T13:08:01.305646Z",
     "shell.execute_reply": "2021-06-28T13:08:01.305224Z",
     "shell.execute_reply.started": "2021-06-28T11:13:13.734902Z"
    },
    "papermill": {
     "duration": 0.020638,
     "end_time": "2021-06-28T13:08:01.305747",
     "exception": false,
     "start_time": "2021-06-28T13:08:01.285109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "\n",
    "# for k, (train_index, test_index) in enumerate(kf.split(df['image'], df['label'])):\n",
    "#     train_img, valid_img = df['image'][train_index], df['image'][test_index]\n",
    "#     train_labels, valid_labels = df['label'][train_index], df['label'][test_index]\n",
    "\n",
    "#     train_paths = '../input/classify-leaves/' + train_img\n",
    "#     valid_paths = '../input/classify-leaves/' + valid_img\n",
    "#     test_paths = '../input/classify-leaves/' + sub_df['image']\n",
    "\n",
    "#     train_dataset = LeafDataset(images_filepaths=train_paths.values,\n",
    "#                                 labels=train_labels.values,\n",
    "#                                 transform=get_train_transforms())\n",
    "#     valid_dataset = LeafDataset(images_filepaths=valid_paths.values,\n",
    "#                                 labels=valid_labels.values,\n",
    "#                                 transform=get_valid_transforms())\n",
    "#     train_loader = DataLoader(\n",
    "#         train_dataset, batch_size=params['batch_size'], shuffle=True,\n",
    "#         num_workers=params['num_workers'], pin_memory=True,\n",
    "#     )\n",
    "\n",
    "#     val_loader = DataLoader(\n",
    "#         valid_dataset, batch_size=params['batch_size'], shuffle=False,\n",
    "#         num_workers=params['num_workers'], pin_memory=True,\n",
    "#     )\n",
    "#     model = LeafNet()\n",
    "#     model = nn.DataParallel(model)\n",
    "#     model = model.to(params['device'])\n",
    "#     criterion = nn.CrossEntropyLoss().to(params['device'])\n",
    "#     optimizer = torch.optim.AdamW(model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
    "\n",
    "#     for epoch in range(1, params['epochs'] + 1):\n",
    "#         train(train_loader, model, criterion, optimizer, epoch, params)\n",
    "#         acc = validate(val_loader, model, criterion, epoch, params)\n",
    "#         torch.save(model.state_dict(), f\"./checkpoints/{params['model']}_{k}flod_{epoch}epochs_accuracy{acc:.5f}_weights.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-stevens",
   "metadata": {
    "papermill": {
     "duration": 0.012938,
     "end_time": "2021-06-28T13:08:01.333007",
     "exception": false,
     "start_time": "2021-06-28T13:08:01.320069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 测试和提交\n",
    "\n",
    "提交用的代码，用了两个模型seresnext50_32x4d和resnet50d。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "neither-grain",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T13:08:01.374691Z",
     "iopub.status.busy": "2021-06-28T13:08:01.374076Z",
     "iopub.status.idle": "2021-06-28T13:14:24.792467Z",
     "shell.execute_reply": "2021-06-28T13:14:24.792868Z",
     "shell.execute_reply.started": "2021-06-28T11:13:13.745015Z"
    },
    "papermill": {
     "duration": 383.446339,
     "end_time": "2021-06-28T13:14:24.793033",
     "exception": false,
     "start_time": "2021-06-28T13:08:01.346694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnext50_32x4d_racm-a304a460.pth\" to /root/.cache/torch/hub/checkpoints/seresnext50_32x4d_racm-a304a460.pth\n",
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet50d_ra2-464e36ba.pth\" to /root/.cache/torch/hub/checkpoints/resnet50d_ra2-464e36ba.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/18353.jpg</td>\n",
       "      <td>asimina_triloba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/18354.jpg</td>\n",
       "      <td>betula_nigra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/18355.jpg</td>\n",
       "      <td>platanus_acerifolia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/18356.jpg</td>\n",
       "      <td>pinus_bungeana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/18357.jpg</td>\n",
       "      <td>platanus_acerifolia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image                label\n",
       "0  images/18353.jpg      asimina_triloba\n",
       "1  images/18354.jpg         betula_nigra\n",
       "2  images/18355.jpg  platanus_acerifolia\n",
       "3  images/18356.jpg       pinus_bungeana\n",
       "4  images/18357.jpg  platanus_acerifolia"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img, valid_img = df['image'], df['image']\n",
    "train_labels, valid_labels = df['label'], df['label']\n",
    "\n",
    "train_paths = '../input/classify-leaves/' + train_img\n",
    "valid_paths = '../input/classify-leaves/' + valid_img\n",
    "test_paths = '../input/classify-leaves/' + sub_df['image']\n",
    "\n",
    "model_name = ['seresnext50_32x4d', 'resnet50d']\n",
    "model_path_list = [\n",
    "    '../input/checkpoints/seresnext50_32x4d_0flod_50epochs_accuracy0.97985_weights.pth',\n",
    "    '../input/checkpoints/seresnext50_32x4d_1flod_50epochs_accuracy0.97872_weights.pth',\n",
    "    '../input/checkpoints/seresnext50_32x4d_2flod_36epochs_accuracy0.97710_weights.pth',\n",
    "    '../input/checkpoints/seresnext50_32x4d_3flod_40epochs_accuracy0.98303_weights.pth',\n",
    "    '../input/checkpoints/seresnext50_32x4d_4flod_46epochs_accuracy0.97899_weights.pth',\n",
    "    '../input/checkpoints/resnet50d_0flod_40epochs_accuracy0.98087_weights.pth',\n",
    "    '../input/checkpoints/resnet50d_1flod_46epochs_accuracy0.97710_weights.pth',\n",
    "    '../input/checkpoints/resnet50d_2flod_32epochs_accuracy0.97656_weights.pth',\n",
    "    '../input/checkpoints/resnet50d_3flod_38epochs_accuracy0.97953_weights.pth',\n",
    "    '../input/checkpoints/resnet50d_4flod_50epochs_accuracy0.97791_weights.pth',\n",
    "]\n",
    "\n",
    "model_list = []\n",
    "for i in range(len(model_path_list)):\n",
    "    if i < 5:\n",
    "        model_list.append(LeafNet(model_name[0]))\n",
    "    if 5 <= i < 10:\n",
    "        model_list.append(LeafNet(model_name[1]))\n",
    "    model_list[i] = nn.DataParallel(model_list[i])\n",
    "    model_list[i] = model_list[i].to(params['device'])\n",
    "    init = torch.load(model_path_list[i])\n",
    "    model_list[i].load_state_dict(init)\n",
    "    model_list[i].eval()\n",
    "    model_list[i].cuda()\n",
    "\n",
    "    \n",
    "labels = np.zeros(len(test_paths)) # Fake Labels\n",
    "test_dataset = LeafDataset(images_filepaths=test_paths,\n",
    "                            labels=labels,\n",
    "                            transform=get_valid_transforms())\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=128, shuffle=False,\n",
    "    num_workers=10, pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "predicted_labels = []\n",
    "pred_string = []\n",
    "preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (images, target) in test_loader:\n",
    "        images = images.cuda()\n",
    "        onehots = sum([model(images) for model in model_list]) / len(model_list)\n",
    "        for oh, name in zip(onehots, target):\n",
    "            lbs = label_inv_map[torch.argmax(oh).item()]\n",
    "            preds.append(dict(image=name, labels=lbs))\n",
    "\n",
    "df_preds = pd.DataFrame(preds)\n",
    "sub_df['label'] = df_preds['labels']\n",
    "sub_df.to_csv('submission.csv', index=False)\n",
    "sub_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 404.768129,
   "end_time": "2021-06-28T13:14:27.019663",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-28T13:07:42.251534",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
